# Changelog

All notable changes to Project A.N.C. will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [3.2.0] - 2025-11-02

### üîÑ Major Update: API Client Architecture Migration

This release migrates Alice Chat from direct SDK integration to an API client architecture, enabling centralized prompt management, RAG operations, and LLM calls on a separate API server.

**UPDATE (2025-11-02):** Fixed model configuration format to match API server expectations.

**UPDATE (2025-11-02 #2):** Removed `gemini_params` from API request config - using server defaults for temperature and max_output_tokens. This fix resolves API errors caused by invalid parameter values.

### Added

#### API Client Architecture
- **HTTP-based Chat API Client** - Alice now communicates with a separate API server
  - `CHAT_API_BASE_URL` configuration for API endpoint
  - `COMPASS_API_KEY` for optional API authentication
  - `/chat/gemini` endpoint integration
  - Request/response JSON logging for debugging

#### New Helper Methods
- **`_convert_to_chat_messages()`** - Converts AppState history to ChatMessage format
  - Filters out image metadata (temporary until API supports images)
  - Returns list of `{role, content}` dictionaries
  - Commented-out future image encoding logic preserved

- **`_build_chat_config()`** - Maps ANC configuration to ChatGeminiConfig format
  - `gemini_params`: temperature, model selection
  - `memory_search_config`: Compass API settings (endpoint, target, limits, search_mode)
  - Dynamically reads from ALICE_CHAT_CONFIG and COMPASS_API_CONFIG

- **`_call_chat_api()`** - Handles HTTP POST requests to Chat API
  - Bearer token authentication support
  - 90-second timeout for long-running requests
  - Comprehensive error handling (HTTPError, Timeout)
  - Returns parsed JSON response

#### Configuration Enhancements
- **`CHAT_API_BASE_URL`** - API server base URL (default: `http://localhost:8000`)
- **`COMPASS_API_KEY`** - Optional API authentication key
- **`ALICE_TEMPERATURE`** - Temperature parameter for LLM (0.0-2.0, default: 1.0)

### Changed

#### Alice Chat Manager (`app/alice_chat_manager.py`)

**Removed Dependencies:**
- ‚ùå `google.genai` - No longer using Gemini SDK directly
- ‚ùå `openai` - No longer using OpenAI SDK directly
- ‚ùå `PIL.Image` - Image handling moved to API server
- ‚úÖ `requests` - Added for HTTP communication

**Removed Methods (Logic moved to API server):**
- `_init_client()` - API client initialization
- `_load_system_instruction()` - System prompt loading
- `_load_long_term_memory()` - Memory file loading
- `_get_past_conversations_from_compass_api()` - RAG search
- `_prepare_contents()` - Prompt construction
- `_load_today_chat_log()` - Today's log retrieval
- `_send_message_gemini()` - Gemini API integration
- `_send_message_openai()` - OpenAI API integration

**Modified Methods:**
- **`__init__()`** - Simplified to API client configuration
  - Removed: `self.client`, `self.api_provider`, `self.system_instruction`, `self.long_term_memory`
  - Added: `self.api_base_url`, `self.api_endpoint`, `self.api_key`

- **`send_message()`** - Complete refactor to API client flow
  - 6-step process: AppState update ‚Üí Request building ‚Üí API call ‚Üí Response handling ‚Üí Logging ‚Üí History trimming
  - Image support temporarily disabled (with warning)
  - Enhanced error messages for HTTP errors and timeouts

- **`_log_dialog()` ‚Üí `_log_api_dialog()`** - Updated for API responses
  - Logs config and message count instead of full prompt contents
  - Structured JSON logging of request/response

- **`is_available()`** - Now checks `CHAT_API_BASE_URL` instead of SDK API keys

**Preserved Methods (No changes required):**
- `_save_to_chat_log()` - Local conversation logging
- `_trim_history()` - History management
- `get_history()` - History retrieval
- `clear_history()` - History clearing
- `get_conversation_summary()` - Conversation statistics
- `export_conversation()` - Conversation export

#### Configuration (`config/config.py`)
- Added `CHAT_API_BASE_URL` (line 121)
- Added `COMPASS_API_KEY` (line 124)
- Added `temperature` to `ALICE_CHAT_CONFIG` (line 133)

#### Environment Variables (`.env.example`)
- Updated `CHAT_API_PROVIDER`, `GEMINI_API_KEY`, `OPENAI_API_KEY` ‚Üí **Deprecated** (commented out)
- Added `CHAT_API_BASE_URL` ‚Üí **Required** for API client
- Added `COMPASS_API_KEY` ‚Üí Optional authentication
- Added `ALICE_TEMPERATURE` ‚Üí Model temperature parameter
- Updated documentation to reflect API client architecture

### Deprecated

- **`CHAT_API_PROVIDER`** - No longer used (API server handles provider selection)
- **`GEMINI_API_KEY`** - No longer used by ANC client (moved to API server)
- **`OPENAI_API_KEY`** - No longer used by ANC client (moved to API server)

### Removed

- **Direct SDK Integration** - Removed Google Gemini and OpenAI SDK dependencies from chat manager
- **Client-side Prompt Construction** - All prompt logic moved to API server
- **Client-side RAG Operations** - Compass API calls now handled by API server
- **Image Support (Temporary)** - Disabled until API server supports image input

### Fixed

- **Separation of Concerns** - Client now focuses on UI/UX, server handles AI logic
- **Centralized Configuration** - All AI settings managed on API server
- **Improved Error Handling** - HTTP-specific error messages for better debugging
- **Model Configuration Format** - Fixed `_build_chat_config()` to match API server expectations
  - Added top-level `config.model` field (API server reads this)
  - ~~Added `config.gemini_params.max_output_tokens` (default: 1024)~~ **REMOVED** - Using server defaults
  - Simplified `memory_search_config` format:
    - Changed to `enabled` boolean (based on `limit > 0`)
    - Changed to `search_type` ("normal" or "graph")
    - Removed unused fields (`endpoint`, `related_limit`, `compress`, `search_mode`)
  - Model selection from `.env` now correctly applied
- **API Parameter Configuration** - Removed `gemini_params` block from request config (2025-11-02 #2)
  - Previously sent invalid values (`temperature: 2`, `max_output_tokens: 1`, etc.)
  - Now uses API server's default parameters for optimal response quality
  - Fixes API errors caused by malformed configuration

### Technical Details

#### API Request Format (Updated - 2025-11-02 #2)
```json
{
  "messages": [
    {"role": "user", "content": "„Åì„Çì„Å´„Å°„ÅØ"},
    {"role": "model", "content": "„ÅØ„ÅÑ„ÄÅ„Åî‰∏ª‰∫∫Êßò"}
  ],
  "config": {
    "model": "gemini-2.5-pro",
    "memory_search_config": {
      "enabled": true,
      "target": "content",
      "limit": 5,
      "search_type": "normal"
    }
  }
}
```

**Note:**
- Config format was updated to match API server expectations. The model is now specified at the top level (`config.model`) rather than nested in `gemini_params`.
- **UPDATE (2025-11-02 #2):** Removed `gemini_params` block entirely. API server now uses its default configuration for temperature and max_output_tokens, ensuring optimal response quality.

#### API Response Format
```json
{
  "response": {
    "content": "„ÅØ„ÅÑ„ÄÅ„Åî‰∏ª‰∫∫Êßò„ÄÇ„ÅäÂëº„Å≥„Åß„Åó„Çá„ÅÜ„Åã?",
    "role": "model"
  },
  "memory_search_results": [...],
  "processing_time": 1.234
}
```

#### File Changes
- **Modified**: `config/config.py` (+4 lines) - API configuration
- **Modified**: `app/alice_chat_manager.py` (-330 lines, +170 lines) - Complete refactor with config format fix
- **Modified**: `.env.example` (+15 lines) - Updated documentation
- **Modified**: `docs/CHANGELOG.md` - This changelog entry

### Performance

- **API Request**: ~50-100ms overhead for HTTP communication
- **Total Response Time**: Depends on API server (typically 1-3s for LLM response)
- **Local Logging**: <10ms (unchanged)
- **Memory Usage**: Reduced by ~50MB (no SDK libraries loaded)

### Breaking Changes

‚ö†Ô∏è **IMPORTANT**: This is a **BREAKING** change if you are upgrading from v3.1.x

#### Required Migration Steps

1. **Set up Chat API Server**
   - Deploy the Chat API server (separate repository)
   - Note the server URL (e.g., `http://localhost:8000`)

2. **Update Environment Variables**
   ```bash
   # Add to .env
   CHAT_API_BASE_URL=http://localhost:8000
   COMPASS_API_KEY=your_api_key_here  # Optional

   # Comment out (no longer used by ANC client)
   # CHAT_API_PROVIDER=google
   # GEMINI_API_KEY=...
   # OPENAI_API_KEY=...
   ```

3. **Restart Application**
   ```bash
   python app/main.py
   ```

#### Image Support Migration

‚ö†Ô∏è **Temporary Limitation**: Image sending is disabled in v3.2.0

- Images are still stored in conversation metadata
- Warning message shown when image is detected
- Will be re-enabled when API server supports image input
- No data loss - image paths preserved in conversation state

### Known Issues

- Image input temporarily disabled (will be restored in v3.2.1)
- API server must be running for Alice Chat to function
- No fallback to SDK if API server is unavailable (intentional design)

### Upgrade Notes

#### From v3.1.0 to v3.2.0

**Prerequisites:**
- Chat API server deployed and accessible
- `CHAT_API_BASE_URL` configured in `.env`

**Migration Checklist:**
- [ ] Deploy Chat API server
- [ ] Update `.env` with `CHAT_API_BASE_URL`
- [ ] (Optional) Set `COMPASS_API_KEY` for authentication
- [ ] Remove or comment out `GEMINI_API_KEY` and `OPENAI_API_KEY`
- [ ] Restart ANC application
- [ ] Test Alice Chat functionality
- [ ] Verify conversation logging still works

**Rollback Plan:**
```bash
git checkout v3.1.0  # Revert to previous version
# Restore old .env settings
```

### Benefits of API Client Architecture

1. **Centralized Logic** - All prompt engineering on API server
2. **Easier Updates** - Change prompts without updating client
3. **Better Security** - API keys only on server, not client
4. **Scalability** - Multiple clients can share one API server
5. **Testability** - Server and client can be tested independently
6. **Flexibility** - Easy to switch LLM providers on server side

---

## [3.1.0] - 2025-10-08

### üé® Major Update: Multi-Conversation Management & Markdown Support

This release introduces powerful conversation management features, allowing users to maintain multiple AI conversations simultaneously with full persistence.

### Added

#### Multiple Conversation Management
- **Tab-based conversation system** - Manage multiple conversations simultaneously
  - Create unlimited conversation tabs
  - Switch between conversations seamlessly
  - Each tab maintains independent conversation history
  - Auto-generated conversation titles from first user message
  - Close individual conversation tabs (with protection for last tab)

#### Markdown Rendering
- **Rich text display** - AI responses now rendered with full Markdown support
  - Code blocks with syntax highlighting
  - Lists (ordered and unordered)
  - Bold, italic, and strikethrough text
  - Tables and blockquotes
  - GitHub-flavored Markdown extensions (`gitHubWeb`)

#### Conversation Persistence
- **Auto-save functionality** - Conversations persist across application sessions
  - JSON-based storage in `data/conversation_state.json`
  - Automatic save on application exit
  - Automatic restore on application startup
  - Preserves all conversation metadata (title, timestamps, messages)

#### Enhanced State Management
- **Multi-conversation support** in `AppState`
  - `create_new_conversation(title)` - Create new conversation sessions
  - `set_active_conversation(session_id)` - Switch active conversation
  - `get_all_conversations()` - Retrieve all conversation states
  - `remove_conversation(session_id)` - Delete conversation sessions
  - `save_conversations(filepath)` - Persist conversations to JSON
  - `load_conversations(filepath)` - Restore conversations from JSON

#### UI Enhancements
- **Conversation controls**
  - "New Conversation" button (blue `+` icon)
  - "Clear History" button (clears active conversation only)
  - "Export Conversation" button (placeholder for future feature)
  - Close button on each conversation tab (√ó)
- **Welcome message** - Initial greeting in new conversations
- **Debug mode** - Comprehensive logging for troubleshooting

### Changed

#### State Manager (`app/state_manager.py`)
- **Breaking**: `_conversation` ‚Üí `_conversations: Dict[str, ConversationState]`
- **Breaking**: Methods now require/return `session_id` for multi-conversation support
- `ConversationState` now includes `title` field
- All conversation methods updated to work with active conversation ID
- Thread-safe operations maintained with RLock

#### UI Architecture (`app/ui_redesign.py`)
- **MainConversationArea** completely refactored for multi-conversation support
  - `conversation_views: Dict[str, ListView]` - Per-conversation UI containers
  - `chat_history_container` - Dynamic container for active conversation
  - `did_mount()` lifecycle method for proper initialization
  - Message routing to correct conversation ListView

#### Main Application (`app/main.py`)
- `AppState` initialized with persistence file path
- `on_page_close()` enhanced with conversation auto-save
- Proper cleanup sequence on application exit

#### Configuration (`config/config.py`)
- Added `DATA_DIR` constant for centralized data directory path
- All data paths now use `DATA_DIR` for consistency

### Fixed

- **UI initialization order** - Resolved "Control must be added to page first" error
- **Message display** - Messages now correctly appear in active conversation
- **Tab visibility** - Fixed layout issues preventing tab display
- **Container updates** - Chat history container properly updates on conversation switch
- **Memory management** - Proper cleanup of conversation views on tab close

### Technical Details

#### Data Structure
```json
{
  "conversations": {
    "session_xxxxx": {
      "session_id": "session_xxxxx",
      "title": "„É¶„Éº„Ç∂„Éº„ÅÆÊúÄÂàù„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏...",
      "messages": [
        {
          "role": "user",
          "content": "„É°„ÉÉ„Çª„Éº„Ç∏ÂÜÖÂÆπ",
          "timestamp": "2025-10-08T10:30:00",
          "metadata": {}
        }
      ],
      "started_at": "2025-10-08T10:30:00",
      "last_message_at": "2025-10-08T11:15:00"
    }
  },
  "active_conversation_id": "session_xxxxx",
  "version": "1.0"
}
```

#### File Changes
- **Modified**: `app/state_manager.py` (+150 lines) - Multi-conversation support
- **Modified**: `app/ui_redesign.py` (+200 lines) - Tab-based UI
- **Modified**: `app/main.py` (+10 lines) - Persistence integration
- **Modified**: `config/config.py` (+1 line) - DATA_DIR constant

### Performance

- **Conversation switching**: <50ms (instant UI update)
- **Persistence save**: <100ms for 10 conversations
- **Persistence load**: <150ms for 10 conversations
- **Memory**: ~5MB per conversation with 100 messages
- **UI responsiveness**: No impact on message rendering

### User Experience

- **Seamless workflow**: Start new conversations without losing context
- **Beautiful formatting**: Markdown rendering improves readability
- **Data safety**: Auto-save prevents conversation loss
- **Easy management**: Close tabs you don't need anymore

### Known Issues

- Export functionality is placeholder (will be implemented in v3.2.0)
- Tab title editing not yet available (planned for v3.2.0)
- No conversation search yet (planned for v3.2.0)

### Upgrade Notes

No breaking changes for end users. All existing data is preserved.
New users will automatically get the enhanced multi-conversation interface.

---

## [3.0.0] - 2025-10-01

### üéâ Major Release: Modern Architecture Refactoring

This release represents a complete architectural overhaul focused on modularity, maintainability, and extensibility.

### Added

#### State Management System
- **AppState class** (`state_manager.py`) - Centralized application state with Observer pattern
  - Thread-safe operations with RLock
  - File state management
  - Conversation state management
  - UI state management
  - Event-driven reactive updates
  - 416 lines of quality state management code

#### Dynamic Plugin System
- **PluginManager** (`plugin_manager.py`) - Automatic plugin discovery and loading
  - Zero-configuration plugin registration
  - Runtime plugin discovery using `importlib`
  - Plugin validation and error handling
  - Capability filtering (async, Ollama, etc.)
  - 302 lines of plugin management code
  - Discovery time: <100ms for 3 plugins

#### UI Component Library
- **Reusable UI Components** (`ui_components.py`) - 8 reusable components
  - `DatePickerButton` - Date selection with picker dialog
  - `ProgressButton` - Button with progress indicator
  - `ExpandableSection` - Collapsible content sections
  - `EditableTextField` - Text editor with save functionality
  - `FileListItem` - Consistent file display items
  - `SectionHeader` - Standardized section headers
  - `SearchField` - Search input with icon
  - `StatusMessage` - Colored status alerts
  - Utility functions for common UI patterns
  - 542 lines of UI component code
  - 40% reduction in UI code duplication

#### Enhanced Async Operations
- **OperationStatus enum** - 5 operation states (pending, running, completed, failed, cancelled)
- **OperationInfo dataclass** - Structured operation metadata
- **Cancellation support** - Thread-safe operation cancellation via `threading.Event`
- **Progress tracking** - Real-time progress updates with callbacks
- **Operation retention** - 60-second retention of completed operations
- Thread-safe with RLock

#### Documentation
- `SYSTEM_OVERVIEW.md` - Comprehensive system architecture (v3.0)
- `ALICE_CHAT_SETUP.md` - Alice setup guide (v3.0)
- `AI_ANALYSIS_SYSTEM.md` - Plugin system documentation (v3.0)
- `PLUGIN_DEVELOPMENT_GUIDE.md` - Detailed plugin development guide (NEW)
- `API_REFERENCE.md` - Complete API documentation (NEW)
- `TESTING_GUIDE.md` - Testing best practices (NEW)
- `DEPLOYMENT.md` - Deployment guide (NEW)
- `TROUBLESHOOTING.md` - Common issues and solutions (NEW)

### Changed

#### Architecture Improvements
- Migrated to centralized state management pattern
- Refactored UI to use reusable component library
- Simplified plugin registration (zero configuration)
- Enhanced async operation tracking and management
- Improved error handling and logging throughout

#### Alice Chat Manager
- Integrated with `AppState` for conversation management
- Enhanced context management with 4-layer system:
  1. Long-term memory (`0-Memory.md`)
  2. Today's chat history
  3. Current session history (AppState)
  4. Latest user message
- Improved error handling and logging
- Better token limit management

#### Plugin System
- **Breaking**: Plugins now auto-discovered (no manual registration needed)
- **Breaking**: Plugin registration moved to `PluginManager`
- Improved plugin validation and error handling
- Better plugin metadata tracking

#### Logger System
- Daily log rotation for all log types (7 types)
- Improved log formatting and structure
- Better performance logging
- Enhanced error tracking

#### UI/UX
- Conversation-first interface design
- Cleaner, more consistent UI across tabs
- Better progress indicators
- Improved error messages
- More responsive UI updates via Observer pattern

### Removed

- **7,000 lines of legacy code removed**
  - Duplicate UI code (replaced with components)
  - Manual plugin registration code
  - Scattered state management
  - Redundant file operations
  - Obsolete utility functions
  - Legacy async patterns
  - Unused imports and dead code

### Fixed

- Thread safety issues in state management
- Plugin discovery race conditions
- Memory leaks in long-running operations
- UI update timing issues
- File operation error handling
- Async operation cancellation edge cases

### Performance

- **Startup time**: ~2-3 seconds (unchanged)
- **Plugin discovery**: <100ms for 3 plugins (new)
- **State updates**: O(1) with observer notifications (new)
- **Memory usage**: ~150MB typical (improved from ~200MB)
- **UI responsiveness**: Significantly improved with state management

### Statistics

- **Code Quality**:
  - 7,000 lines removed
  - 1,800 lines of quality code added
  - Net reduction: -5,200 lines (-40%)
  - Improved modularity and maintainability

- **Architecture**:
  - 1 centralized state manager
  - 1 dynamic plugin manager
  - 8 reusable UI components
  - 3 auto-discovered plugins
  - 7 daily-rotated log types

## [2.0.0] - 2025-09-15

### Added

#### AI Analysis Plugin System
- Plugin-based architecture for AI analysis
- Base plugin interface (`BaseAnalysisPlugin`)
- AI Analysis Manager for plugin coordination
- Three initial plugins:
  - Tagging Plugin (AI-powered keyword extraction)
  - Summarization Plugin (text summarization)
  - Sentiment Plugin (sentiment analysis)

#### Ollama Integration
- Local AI analysis via Ollama
- Support for multiple models (llama3.1, gemma2, etc.)
- Async analysis with progress tracking
- Retry logic with exponential backoff

#### Database Enhancements
- AI analysis results storage
- Plugin metadata tracking
- Analysis history

### Changed
- Refactored analysis code into modular plugins
- Improved async operation handling
- Enhanced error handling and logging

### Performance
- Async analysis for better UI responsiveness
- Progress callbacks for long-running operations
- Cancellation support

## [1.0.0] - 2025-08-01

### Added

#### Core Features
- Desktop application built with Flet
- File management system (notes, memories, nippo)
- TinyDB for metadata storage
- Basic text editor functionality

#### Alice AI Chat
- Google Gemini API integration
- Conversation history management
- System prompt and long-term memory
- Daily chat logs

#### File Operations
- Create, read, update, delete files
- File categorization (notes, memories, nippo)
- Basic tagging system
- File search and filtering

#### UI
- Sidebar navigation
- Multiple tabs for different functions
- File list view
- Text editor

#### Logging
- Basic logging system
- Error tracking
- File operation logs

### Technical Details
- Python 3.12+
- Flet 0.21.0+
- TinyDB 4.8.0+
- Google Generative AI 1.38+

## Versioning Strategy

Project A.N.C. follows Semantic Versioning:

- **MAJOR** version (X.0.0): Incompatible API changes or major architecture overhauls
- **MINOR** version (0.X.0): New features, backwards-compatible
- **PATCH** version (0.0.X): Bug fixes, backwards-compatible

### Version History

- **v3.2.0** (2025-11-02): API client architecture migration - centralized LLM/RAG on API server
- **v3.1.0** (2025-10-08): Multi-conversation management with Markdown support and persistence
- **v3.0.0** (2025-10-01): Modern architecture with state management and dynamic plugins
- **v2.0.0** (2025-09-15): Plugin-based AI analysis system
- **v1.0.0** (2025-08-01): Initial release with core features

## Upgrade Guide

### Upgrading from v3.1 to v3.2

#### Breaking Changes - API Client Migration

This is a **BREAKING** update that requires external API server setup.

**Migration Steps:**

1. **Deploy Chat API Server** (separate repository)
   ```bash
   # Clone and run the Chat API server
   # Example: https://github.com/your-org/anc-chat-api
   cd anc-chat-api
   python main.py
   # Server will run on http://localhost:8000 by default
   ```

2. **Update `.env` file**
   ```bash
   # Add new required settings
   CHAT_API_BASE_URL=http://localhost:8000
   COMPASS_API_KEY=your_api_key_here  # Optional

   # Comment out deprecated settings
   # CHAT_API_PROVIDER=google
   # GEMINI_API_KEY=...
   # OPENAI_API_KEY=...
   ```

3. **Restart ANC Application**
   ```bash
   python app/main.py
   ```

4. **Verify Functionality**
   - Send a message to Alice
   - Check that responses are received
   - Verify conversation logging works
   - Check `logs/dialogs/` for API call logs

**Rollback Instructions:**
```bash
git checkout v3.1.0
# Restore old .env with SDK API keys
```

**Known Limitations in v3.2.0:**
- Image input temporarily disabled (will be restored in v3.2.1)
- Requires API server to be running (no SDK fallback)

### Upgrading from v3.0 to v3.1

#### Non-Breaking Update

This is a **minor version update** with no breaking changes. Simply pull the latest code and restart the application.

#### New Features Available Immediately

1. **Multiple Conversations**
   - Click the blue `+` button to create new conversation tabs
   - Click the `√ó` on any tab to close it (last tab protected)
   - Switch between tabs to access different conversation contexts

2. **Markdown Formatting**
   - All AI responses automatically rendered with Markdown
   - Code blocks, lists, tables all supported
   - No configuration needed

3. **Conversation Persistence**
   - All conversations automatically saved on exit
   - Restored on next startup
   - Data stored in `data/conversation_state.json`

#### Optional Cleanup

If you want to start fresh:
```bash
# Remove old conversation data (optional)
rm data/conversation_state.json
```

### Upgrading from v2.0 to v3.0

#### Breaking Changes

1. **Plugin Registration**
   - **Old**: Manual registration in `AppLogic._setup_ai_plugins()`
   ```python
   self.ai_manager.register_plugin(TaggingPlugin())
   ```
   - **New**: Automatic discovery (no code changes needed)
   ```python
   # Just place plugin in app/ai_analysis/plugins/
   # PluginManager discovers automatically
   ```

2. **State Management**
   - **Old**: Direct state manipulation
   ```python
   self.files[path] = metadata
   ```
   - **New**: Use AppState
   ```python
   app_state.add_file(path, metadata)
   ```

3. **UI Components**
   - **Old**: Custom UI code in each file
   - **New**: Import from ui_components
   ```python
   from app.ui_components import ProgressButton, ExpandableSection
   ```

#### Migration Steps

1. **Update Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Update Plugin Registration**
   - Remove manual registration code
   - Ensure plugins are in `app/ai_analysis/plugins/`
   - Restart application

3. **Update State Access**
   - Replace direct state access with `AppState` methods
   - Add observers for reactive updates

4. **Update UI Code**
   - Replace custom UI with reusable components
   - Import from `ui_components.py`

5. **Test Application**
   ```bash
   python app/main.py
   # Verify plugins discovered in logs
   # Test all functionality
   ```

### Upgrading from v1.0 to v2.0

#### Migration Steps

1. **Install Ollama**
   ```bash
   # Download from ollama.com
   ollama pull llama3.1:8b
   ```

2. **Update Configuration**
   ```python
   # config/config.py
   OLLAMA_MODEL = "llama3.1:8b"
   ```

3. **Test AI Analysis**
   - Run tagging analysis
   - Verify Ollama connection
   - Check analysis results in database

## Future Roadmap

### v3.2.0 (Planned)
- [ ] Conversation title editing (double-click to rename)
- [ ] Conversation search across all tabs
- [ ] Export conversation to Markdown file
- [ ] Conversation templates
- [ ] Plugin configuration UI
- [ ] Custom prompt templates
- [ ] Analysis result caching

### v3.3.0 (Planned)
- [ ] Hot-reload plugins without restart
- [ ] Plugin dependency management
- [ ] Parallel plugin execution
- [ ] Performance profiling dashboard

### v4.0.0 (Future)
- [ ] Web interface
- [ ] Multi-user support
- [ ] Cloud synchronization
- [ ] Plugin marketplace

## Contributing

When contributing to this project, please:

1. Follow semantic versioning for changes
2. Update CHANGELOG.md with your changes
3. Add appropriate version tags to commits
4. Include breaking change notices for major versions

### Changelog Entry Format

```markdown
### Added
- New feature description

### Changed
- Modified feature description

### Deprecated
- Feature to be removed

### Removed
- Removed feature description

### Fixed
- Bug fix description

### Security
- Security fix description
```

---

**Maintained By:** Project A.N.C. Team
**Last Updated:** November 2, 2025
**Current Version:** v3.2.0
